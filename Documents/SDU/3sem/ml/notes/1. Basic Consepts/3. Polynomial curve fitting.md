With dataset $S={(x_1,y_1),(x_2,y_2),dots,(x_n,y_n)}$ it is wise to split data into the following:
- Training set, where the learning algorithm will find a $h$ that minimizes $L(h)$
- Test set, check how well the algorithm is doing (are we closer to approximating $f(x)$?) This is ofc assuming i.i.d.

We can use polynomial fitting instead

$$y(x) = sum_(m=0)^M w_m x^m$$ Then by *ridge regression* $w=(X^T X+lambda I)^(-1)X^T Y$
We can predict $y$ by $x^T w$ 
![[Pasted image 20260119123637.png]]
(example of this)

For each order ($m$) we can calculate the risk with the **Root Mean Squared Error (RMSE)**
$$L_S := \sqrt{\frac{1}{m} \sum_{i \in [m]} (h(x_i) - y_i)^2}$$![[Pasted image 20260119123935.png]]
(example)

This should by theory then go down (risk should decrease as the algorithm learns)

Notice that at $M=7$ the model overfits and acts poorly

This is because of very small or large weights
- at a small $m$, model will likely underfit
- at a high $m$, model will likely overfit

To avoid this we use a **regularizer** $h_S := \arg \min_h L_S(h) + \lambda w_m^2$
![[Pasted image 20260119193706.png]]
This mitigates over/under-fitting as polynomial degree increases