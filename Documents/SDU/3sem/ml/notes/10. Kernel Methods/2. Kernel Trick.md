Suppose that $T(x)$ is a mapping to a higher dimension

Note that algorithms like SVM only need **dot products**

That means that with$$k(x_i,x_j) = \phi(x_i)^T\phi(x_j)$$
Because of the definition of the inner product, we can describe the relation between two points using $k(x_i,x_j)$


Computing $\phi(x)$ explicitly can be **very expensive or infinite-dimensional**

- **Linear Kernel:** $k(x,y) = x^\top y$
- **Polynomial Kernel:** $k(x,y) = \left( x^\top y + c \right)^d$
- **Radial Basis Function (RBF) Kernel:** $k(x,y) = \exp(-\frac{\| x-y \|^2}{2\sigma^2})$
- **Sigmoid Kernel:** $k(x,y) = \tanh\left( \gamma x^\top y + c \right)$
