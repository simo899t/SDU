#### Realizability
A hypothesis space $\mathcal{H}$ is realizable with respect to a loss $\ell$ and data distribution $D$ if $$exists h^* in cal(H) " such that " R(h)=0$$It trivially follows from this definition that $\min_{h \in \mathcal{H}} \widehat{R}_S(h)=0$ with probability 1 for a sample set $S$ collected i.i.d. from $D$. 
Hence, under the realizability assumption, all Empirical Risk Minimization (ERM) solutions $$h_S \in \arg \min_{h \in \mathcal{H}} \widehat{R}_S(h)$$ give zero error.

- In other words, the hypothesis class $cal(H)$ is **rich enough** to contain the “true function.” (label function)
- If this is true, it is **possible** to achieve zero training error **and** zero true error.

This is just an assumption that makes PAC learning easier.

#### Representativeness
A training set $S$ is called $\epsilon$-representative if
$$\forall h \in \mathcal{H}, |R(h) - \widehat{R}_S(h)| \leq \epsilon$$
This means that all hypothesis in the h-space, their risk must be epsilon similar to the generalization error

Intuition: The dataset is $epsilon$-representative if there exists a hypothesis with *minimal* error.

#### Uniform convergence
A hypothesis class $\mathcal{H}$ has the **uniform convergence property** if there exists a function $m_{\mathcal{H}}^{\text{UC}} : (\epsilon, \delta)^2 \to \mathbb{N}$ such that for every $\epsilon, \delta \in (0, 1)$ and every distribution $D$, any sampled dataset $S=\{(x_i,y_i) \overset{i.i.d.}{\sim} D : i = 1, \ldots, m\}$ is $\epsilon$-representative with probability at least $1-\delta$.

This means that there exists a function that can tell how many data points you would need for a hypothesis, to know that for all distributions. It is $epsilon-$ representative with a $1-delta$ probability certainty

#### Agnostic PAC learnability
A hypothesis class $\mathcal{H}$ is **agnostic PAC learnable** if there exist a function $m_{\mathcal{H}}: (\epsilon, \delta)^2 + h <- A(S)$ and a **learning algorithm** $A$ such that for every $\epsilon, \delta \in (0, 1)$ and every distribution $D$, running the learning algorithm on dataset $S=\{(x_i,y_i) \overset{i.i.d.}{\sim} D : i = 1, \ldots, m\}$ with $m \ge m_{\mathcal{H}}(\epsilon, \delta)$ satisfies the following

$$P(\{S \sim D: R(A(S)) \le \min_{h' \in \mathcal{H}} R(h') + \epsilon\}) \geq 1-\delta.$$
This means that a hypothesis class $cal(H)$ is **agnostic PAC learnable** if we can guarantee that with enough data, we can find a hypothesis that performs almost as well as the best possible hypothesis in our class.

1. **"Agnostic"** = We don't assume there's a perfect hypothesis in $cal(H)$ that makes zero errors. We're realistic about the fact that our hypothesis class might not contain the true underlying function.
	- (if $"min"_(cal(H))R(h) =0$ and $cal(H)$ is agn. PAC learnable, then $cal(H)$ is PAC learnable)

2. **"PAC"** = "Probably Approximately Correct" - we get performance guarantees that are:
    - **Probably**: With high probability (at least $1−delta$)
    - **Approximately**: Within $epsilon$ error of the best possible
    - **Correct**: We can make this guarantee

3. **The guarantee**: If we have enough training data $(m<=cal(H)(epsilon,delta)$), then our learning algorithm $A$ will find a hypothesis that performs within $epsilon$ of the best possible hypothesis in $H$.

**In practical terms:**
- $epsilon$ = How close we want to be to optimal (smaller = better)
- $delta$ = How confident we want to be (smaller = more confident)
- $m_(cal(H))(ϵ,δ)$ = Minimum number of training examples needed
- The algorithm guarantees: $R(A(S))<="min"_(h in cal(H))​R(h)+epsilon$ with probability $≥1−δ$

#### Bayes Error
Bayes error is the best achievable error once unavoidable factors like noise are taken into account.$$R^*="min"_(h´ in cal(H))R(h´)$$ This means that:
- Even with a perfect model and infinite data, you **cannot do better** than this error.
- The remaining error is due to **irreducible uncertainty**, such as:
    - noise in the data,
    - overlapping class distributions,
    - inherent randomness in the labels.
    
Then a hypothesis class is **PAC learnable** with respect to a data distribution $D$ if it admits zero Bayes error, i.e., $R^* = 0$.

