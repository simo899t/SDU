It is not always convenient to describe sets. We can facilitate this by defining a random variable.

A **random variable** is function $X: \Omega \rightarrow \Lambda$ that maps each elementary event $\omega \in \Omega$ to an element on its **range** $\lambda \in \Lambda$. We can define a probability measure on $\Lambda$ as follows: $$P_X(A) := P(\{\omega \in \Omega: X(\omega) \in A\})$$
where $A \subset \Lambda$. This is called the **induced probability measure** of $X$. 

**Intuition:** **measures the outcome** as a number.

#### Example of random variable
Consider the experiment of tossing a fair coin three times and denote heads by $H$ and tails by $T$. The sample space for this experiment is $\Omega = \{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\}$. 

Because the coin is fair
$$P(H) = P(T) = \frac{1}{2}$$
Because the coin tosses are independent events, we have
$$P(HHH) = P(H)P(H)P(H) = \frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8}$$
and likewise for all other outcomes. Let $X$ be the number of heads in a sequence. Then $X$ is a random variable with range $\Lambda = \{0,1,2,3\}$. The induced probability measure of $X$ is:
1. $P_X(0) = P(\{TTT\}) = \frac{1}{8}$
2. $P_X(1) = P(\{TTH, THT, HTT\}) = \frac{3}{8}$
3. $P_X(2) = P(\{HTH, HHT, THH\}) = \frac{3}{8}$
4. $P_X(3) = P(\{HHH\}) = \frac{1}{8}$

Let us give another example. Let us make up two random variables from the outcome of the roll of a fair die:
1. $X$ is the outcome of the die itself i.e. $\Lambda = \{1,2,3,4,5,6\}$.
2. $Y$ is whether the outcome of the die is even or odd, i.e. $\Lambda = \{even, odd\}$.

Then consider the case of the joint event $P(X \leq 4 \cap Y = even) = P(\{2,4\}) = \frac{2}{6}$.

Marginalization
- For the following $P(X=x,Y=y)$ where $Y$ is binary (like even odd) 	
- Because of this we can drop one of them 
$$P(X=x)=sum_(y={E,O})P(X=x|Y=y)P(Y=y)$$
- and so$$P(X=x) = 1/2 P(X=x|Y=E)+1/2P(X=x|Y=O)$$