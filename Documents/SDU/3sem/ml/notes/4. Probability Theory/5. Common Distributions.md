- Benoulli
	- Binary output (coinflip, yes/no ect.)
	- $P_X (x)=p^x (1-p)^(1-x)$ 
	- this way $P_X (1) = p$ and $P_X (0)=1-p$ 
	- Then $EE[X]=p$ and $"Var"[X]=p(1-p)$
- Beta
	- The Beta distribution elegantly captures both our **belief about the center** and our **confidence in that belief**!
	- $$f_X (x)= Gamma(alpha + beta)/(Gamma(alpha)Gamma(beta))x^(alpha-1)(1-x)^(beta-1) $$
	- where $Gamma(alpha + beta)/(Gamma(alpha)Gamma(beta))$ is the beta function $Beta(alpha, beta)^(-1)$
	- Note that $Gamma(x) =(x-1)!$
	- - $x^(alpha−1)$: Controls the behavior near $x=0$
	- $(1−x)^(beta−1)$: Controls the behavior near $x=1$
	- Together they create the characteristic Beta shape
		- ![[beta_function.png|500]]
		- **Example**:
			1. Prior: Beta(1,1) - "No idea about coin bias"
			2. Flip coin 10 times: 7 heads, 3 tails
			3. Posterior: Beta(1+7, 1+3) = Beta(8,4)
			4. New belief: Coin is probably biased toward heads
	
	![[beta_dist.png]]

- Multi-noulli
	- **Concrete Example: Rolling a die**
		If XX represents the outcome of rolling a 6-sided die:
		- $P_X (1)$ = "probability of rolling a 1"
		- $P_X (2)$ = "probability of rolling a 2"
		- $P_X (6)$ = "probability of rolling a 6"
		
		**For a fair die**: $P_X (1)=P_X (2)=dots=P_X (6)=1/6$
		**For a biased die**: Maybe $P_X( 6)=0.5$ and others are $0.1$ each
	![[multi-nouli_dist.png]]
	
- Dirichlet
	- $$f_X (x)=frac(Gamma(sum^d_(i=1)alpha_1),product^d_(i=1)Gamma(alpha_i))$$
	![[dirichlet_dist.png]]
	- **Example: Website A/B/C Testing**
		1. **Prior**: Dirichlet(1, 1, 1) - "no preference between variants"
		2. **Observe**: Variant A: 20 clicks, B: 15 clicks, C: 10 clicks
		3. **Posterior**: Dirichlet(21, 16, 11) - "updated beliefs"
		4. ***repeat***
		5. At the end use results to predict new observations
- Uniform
	- **The constant $1/(b−a)$​:**
		- This is the **height** of the rectangular probability density
		- **Why this value?** Because the area must equal 1 (total probability)
		- **Area = height × width = $1/2(b−a)(b-a)=1$​ ✓
		- $EE[X]$ is the **midpoint** of the interval - so perfectly symmetric
		- $"Var"[X]$ Depends on the **width** of the interval
			- Wider interval → more spread → higher variance
	- **Intuitive Understanding**
		**"All outcomes equally likely"** - that's the essence of uniform distribution.
	- ![[Pasted image 20251115113127.png]]
	
	- **Examples:**
		- **Fair die**: Each face has probability 1661​ (discrete uniform)
		- **Random time**: Arrival uniformly distributed between 2:00 PM and 4:00 PM
		- **Random number generator**: Most computers generate uniform random numbers on [0,1]
	
- Gaussian
	- Mean: $mu$
	- Standard deviation: $sigma$
	- $$ f_X (x)=cal(N)(x|mu,sigma^2) = 1/sqrt(2pi sigma^2) e^(-1/2((x-mu)/(sigma^2))^2)$$
	- where $$P(a<x<b)=integral^b_a f(x)"  "d x $$
	- Here  $1/sqrt(2pi sigma^2)$ is the normalization, meaning that $$integral_(-infinity)^(infinity) e^(-1/2((x-mu)/(sigma^2))^2)= sqrt(2pi sigma^2)$$
	- and so $$ integral_(-infinity)^(infinity) 1/sqrt(2pi sigma^2) e^(-1/2((x-mu)/(sigma^2))^2) = 1$$
	- ![[gaussian_dist.png]]
- Multivariable Gaussian 
	- $$f_X (x)=cal(N)(x|mu,Sigma)=1/sqrt(((2pi)^2)norm(Sigma))dot e^(-1/2(x-mu)^T Sigma^(-1)(x-mu) )$$
	- ![[multivariable_gaussian_dist.png]]
	- for the parameters $$mu=vec(0,0) quad quad Sigma = mat(1,0;0,1)$$