{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI512: Introduction to Machine Learning\n",
    "## University of Southern Denmark - IMADA\n",
    "### Fall 2024 - Melih Kandemir\n",
    "\n",
    "---\n",
    "# Exercise 07\n",
    "\n",
    "- Develop a generative classifier that fits a normal distribution on each class conditional.\n",
    "- Learn the free parameters with maximum likelihood estimation on Iris data set.\n",
    "- Calculate the posterior class probabilities by Bayes rule. Let the model make predictions based on the most probable class.\n",
    "-  Report the confusion matrix, calculate class-specific accuracy, precision, recall, and F1 score.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following generative classifier:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{x} \\mid y=k) &= \\mathcal{N}(\\mathbf{x} \\mid \\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k) \\\\\n",
    "P(y=k) &= \\pi_k\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where $\\mathcal{N}(\\mathbf{x} \\mid \\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k)$ is a multivariate normal distribution with mean $\\boldsymbol{\\mu}_k$ and covariance $\\boldsymbol{\\Sigma}_k$ and\n",
    "$\\pi_k$ is the prior probability of class $k$. \n",
    "\n",
    "Remark: $p(\\cdot)$ is a probability density function and $P(\\cdot)$ is a probability mass function.\n",
    "\n",
    "**Question 1**: Write down the joint distribution of the above model for the training data $S = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^m$ where\n",
    "the prior probabilities $\\pi_k$ are fixed to the empirical class frequencies, i.e. $\\pi_k = \\frac{1}{m} \\sum_{i=1}^m \\mathbb{1}(y_i = k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Express the maximum likelihood estimation problem for learning the parameters $\\boldsymbol{\\mu}_k$, $\\boldsymbol{\\Sigma}_k$ of the model above for all classes $k$ as an optimization problem.\n",
    "\n",
    "**Hint:** Write down the log-likelihood function of the class-conditionals for each class $k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Write down the predictive distribution of the model trained in Question 2 for a new data point $\\mathbf{x}_*$.\n",
    "\n",
    "**Hint:** Use Bayes rule to combine the \"learned\" class conditionals $p(\\mathbf{x}_i \\mid y=k)$ with the assumed class priors $\\pi_k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Write down the Bayes classifier for the predictive distribution developed in Question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Implement the generative classifier with maximum likelihood estimation (Questions 2, 3, 4) on the Iris data set using the following template in Numpy. \n",
    "\n",
    "**Hint:** Create an instance of the class `GenerativeClassifier` and call the method `learn` with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "\n",
    "class GenerativeClassifier:\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(GenerativeClassifier, self).__init__()\n",
    "        self.D = input_dim\n",
    "        self.K = num_classes\n",
    "        self.mu = np.zeros((self.K, self.D))\n",
    "        self.Sigma = np.zeros((self.K, self.D, self.D))\n",
    "\n",
    "    def learn(self, X, y):\n",
    "        \"\"\"\n",
    "            Learn the parameters of the model.\n",
    "            X: training data shape: (N, D)\n",
    "            y: training labels shape: (N,)\n",
    "            Question 2\n",
    "        \"\"\"\n",
    "\n",
    "        self.class_prob = np.zeros(self.K)\n",
    "        for k in range(self.K):\n",
    "            self.class_prob[k] = np.sum(y == k) / y.shape[0]\n",
    "\n",
    "        # Fill the rest of the function\n",
    "\n",
    "\n",
    "\n",
    "    def log_gaussian(self, X, mu, Sigma):\n",
    "        \"\"\"\n",
    "            Compute the log probability of X under a Gaussian distribution with mean mu and covariance Sigma to be used in predict function.\n",
    "            X: data shape: (N, D)\n",
    "            mu: mean shape: (D,)\n",
    "            Sigma: covariance shape: (D, D)\n",
    "            Return: log probability of X shape (N,)\n",
    "            Question 3\n",
    "        \"\"\"            \n",
    "        # Fill the function\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Predict the class of each data point in X.\n",
    "            X: data\n",
    "            Return: predicted labels\n",
    "            Question 4\n",
    "            Note: Use log_gaussian function and do not forget the prior probability of each class.\n",
    "        \"\"\"\n",
    "        # Fill the function\n",
    "\n",
    "\n",
    "\n",
    "# load the iris data set\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split into training and test set\n",
    "n_samples = X.shape[0]\n",
    "n_train = int(0.8 * n_samples)\n",
    "n_test = n_samples - n_train\n",
    "\n",
    "idx = np.random.permutation(n_samples)\n",
    "\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "X_train = X[:n_train]\n",
    "\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]\n",
    "\n",
    "# Fill the rest of the code\n",
    "\n",
    "# Create the model\n",
    "model = \n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**: Predict the class labels of the test split of the Iris data set using the Bayes classifier and calculate the confusion matrix, class-specific accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Fill the rest of the code\n",
    "\n",
    "# Evaluate the model\n",
    "# Calculate Accuracy on test set\n",
    "acc = \n",
    "print(f\"Accuracy: {acc.item()}\")\n",
    "\n",
    "# Calculate Confusion Matrix on test set\n",
    "confusion_matrix = \n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Calculate Precision and recall\n",
    "precision =\n",
    "recall = \n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
